{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5caa594",
   "metadata": {},
   "source": [
    "# CS 559: Final Project - Individual Part\n",
    "Zheng Ke Xu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a2e717",
   "metadata": {},
   "source": [
    "## 1. Subgroup 2379\n",
    "Goal is to apply 3 different supervised learning models. We're going to rely on gridsearch CV to perform cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f803c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#we can actually apply this notebook to any subgroup. All subgroups are already preprocessed\n",
    "df = pd.read_csv('./subgroup_2379.csv')\n",
    "\n",
    "#Splitting data into \n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = train_set.drop(columns='Bankrupt?')\n",
    "y_train = train_set['Bankrupt?']\n",
    "\n",
    "x_test = test_set.drop(columns='Bankrupt?')\n",
    "y_test = test_set['Bankrupt?']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7e3319",
   "metadata": {},
   "source": [
    "### Part 1.1: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3665f3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Tuning time: 0.13389945030212402\n",
      "\n",
      "R2 values: \n",
      "   mean_score_time  mean_test_score  rank_test_score\n",
      "0         0.015133         0.998424                1\n",
      "1         0.019900         0.998424                1\n",
      "2         0.024429         0.998424                1\n",
      "3         0.027766         0.997898                4\n",
      "4         0.025376         0.997898                4\n",
      "5         0.025829         0.997898                4\n",
      "6         0.024293         0.997898                4\n",
      "7         0.021318         0.997898                4\n",
      "8         0.018701         0.997898                4\n",
      "\n",
      "Best SVM parameters: {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#Training model and cross validation\n",
    "svc = SVC(kernel='rbf', gamma='auto')\n",
    "\n",
    "param_grid_svc = {\n",
    "    'C': range(1, 10, 1)\n",
    "}\n",
    "\n",
    "grid_search_svc = GridSearchCV(\n",
    "    estimator=svc,\n",
    "    param_grid=param_grid_svc,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search_svc.fit(x_train, y_train)\n",
    "end_time = time.time()\n",
    "tuning_time = end_time - start_time\n",
    "\n",
    "svc = grid_search_svc.best_estimator_\n",
    "svc_param = grid_search_svc.best_params_\n",
    "svc_results = pd.DataFrame(grid_search_svc.cv_results_)\n",
    "\n",
    "print(\"Tuning time: \" + str(tuning_time) + \"\\n\")\n",
    "print(\"R2 values: \\n\" + str(svc_results[['mean_score_time', 'mean_test_score', 'rank_test_score']]) + \"\\n\")\n",
    "print(\"Best SVM parameters: \" + str(svc_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "158bdb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC accuracy score 1.0\n"
     ]
    }
   ],
   "source": [
    "#Testing model SV\n",
    "svc_pred = svc.predict(x_test)\n",
    "svc_acc = accuracy_score(y_test, svc_pred)\n",
    "\n",
    "print(f\"SVC accuracy score {svc_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e2d3d9",
   "metadata": {},
   "source": [
    "### Part 1.2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6ee1cd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Tuning time: 0.048276424407958984\n",
      "\n",
      "R2 values: \n",
      "    mean_score_time  mean_test_score  rank_test_score\n",
      "0          0.001305         0.998424                1\n",
      "1          0.001251         0.998424                1\n",
      "2          0.001281         0.998424                1\n",
      "3          0.001251         0.998424                1\n",
      "4          0.001194         0.998424                1\n",
      "5          0.001308         0.998424                1\n",
      "6          0.001432         0.998424                1\n",
      "7          0.001435         0.998424                1\n",
      "8          0.001277         0.998424                1\n",
      "9          0.001244         0.998424                1\n",
      "10         0.001035         0.997373               12\n",
      "11         0.000934         0.997898               11\n",
      "\n",
      "Best logistic regression parameters: {'C': 0.0001, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Training model and cross validation\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "param_grid_logreg = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid_search_logreg = GridSearchCV(\n",
    "    estimator=logreg,\n",
    "    param_grid=param_grid_logreg,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search_logreg.fit(x_train, y_train)\n",
    "end_time = time.time()\n",
    "tuning_time = end_time - start_time\n",
    "\n",
    "logreg = grid_search_logreg.best_estimator_\n",
    "logreg_param = grid_search_logreg.best_params_\n",
    "logreg_results = pd.DataFrame(grid_search_logreg.cv_results_)\n",
    "\n",
    "print(\"Tuning time: \" + str(tuning_time) + \"\\n\")\n",
    "print(\"R2 values: \\n\" + str(logreg_results[['mean_score_time', 'mean_test_score', 'rank_test_score']]) + \"\\n\")\n",
    "print(\"Best logistic regression parameters: \" + str(logreg_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d0f03c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy score 1.0\n"
     ]
    }
   ],
   "source": [
    "#Testing model Logistic Regression\n",
    "logreg_pred = logreg.predict(x_test)\n",
    "logreg_acc = accuracy_score(y_test, logreg_pred)\n",
    "\n",
    "print(f\"Logistic Regression accuracy score {logreg_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a678892",
   "metadata": {},
   "source": [
    "### Part 1.3: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "869ef292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Tuning time: 0.025127410888671875\n",
      "\n",
      "R2 values: \n",
      "   mean_score_time  mean_test_score  rank_test_score\n",
      "0         0.001381         0.998424                1\n",
      "1         0.001338         0.998424                1\n",
      "2         0.001263         0.998424                1\n",
      "3         0.001354         0.998424                1\n",
      "4         0.000884         0.998424                1\n",
      "5         0.000812         0.998424                1\n",
      "\n",
      "Best Naive Bayes parameters: {'var_smoothing': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Training model and cross validation\n",
    "naiveB = GaussianNB()\n",
    "\n",
    "param_grid_naiveB = {\n",
    "    'var_smoothing': [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid_search_naiveB = GridSearchCV(\n",
    "    estimator=naiveB,\n",
    "    param_grid=param_grid_naiveB,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search_naiveB.fit(x_train, y_train)\n",
    "end_time = time.time()\n",
    "tuning_time = end_time - start_time\n",
    "\n",
    "naiveB = grid_search_naiveB.best_estimator_\n",
    "naiveB_param = grid_search_naiveB.best_params_\n",
    "naiveB_results = pd.DataFrame(grid_search_naiveB.cv_results_)\n",
    "\n",
    "print(\"Tuning time: \" + str(tuning_time) + \"\\n\")\n",
    "print(\"R2 values: \\n\" + str(naiveB_results[['mean_score_time', 'mean_test_score', 'rank_test_score']]) + \"\\n\")\n",
    "print(\"Best Naive Bayes parameters: \" + str(naiveB_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fd5b0031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy score 1.0\n"
     ]
    }
   ],
   "source": [
    "#Testing model Naive Bayes\n",
    "naiveB_pred = naiveB.predict(x_test)\n",
    "naiveB_acc = accuracy_score(y_test, naiveB_pred)\n",
    "\n",
    "print(f\"Naive Bayes accuracy score {naiveB_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af24e18a",
   "metadata": {},
   "source": [
    "## 2. Stacking Model\n",
    "Combine our 3 base models into a stacking model. Our meta learner is Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "039ba945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked model score 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "#Training stacked models\n",
    "estimators = [\n",
    "    ('svc', svc),\n",
    "    ('logreg', logreg),\n",
    "    ('naiveB', naiveB)\n",
    "]\n",
    "\n",
    "meta_learner = LogisticRegression(solver='liblinear')\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=meta_learner,\n",
    "    cv=3,\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "stacking_model.fit(x_train, y_train)\n",
    "stack_pred = stacking_model.predict(x_test)\n",
    "stack_acc = accuracy_score(y_test, stack_pred)\n",
    "\n",
    "print(f\"Stacked model score {naiveB_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc91009",
   "metadata": {},
   "source": [
    "This data set is very sparse and may not necessarily be a good representative of the final model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
